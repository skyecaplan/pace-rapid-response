{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "deac81fc-b6df-46a9-b370-c296f615e800",
   "metadata": {},
   "source": [
    "### PACE_L3_basicplot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf5f2a7-da3a-42a3-8c10-0aede49c0098",
   "metadata": {},
   "source": [
    "This notebook is for basic Level 3 plots. \n",
    "\n",
    "It uses the Earthaccess and Xarray libraries for data search. This means it is intended for provisional and standard products available on Earthdata search. All relevant information is intended to be specified in the \"Identify and search product, specify plotting parameters\" cell. \n",
    "\n",
    "If multiple images are found \n",
    "Results are plotted to the screen and saved as a .png file. \n",
    "\n",
    "NOTE:\n",
    " - For many granules, it may be better to use L3 products\n",
    " - Currently only works for 2D data products. 3D implementation to be specified\n",
    " - Interpolation is subject to error, use with caution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d59b6e6e-5d94-4c3e-8973-0bb691761bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from scipy.interpolate import griddata\n",
    "import earthaccess\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import os\n",
    "from sklearn.neighbors import KDTree\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0280ec0-43c3-468f-a7a1-82ba984294b8",
   "metadata": {},
   "source": [
    "### Earthdata Authentication\n",
    "We authenticate using our Earthdata Login credentials. Authentication is not needed to search publicly available collections in Earthdata, but is always needed to access data. We can use the login method from the earthaccess package. This will create an authenticated session when we provide a valid Earthdata Login username and password. The earthaccess package will search for credentials defined by environmental variables or within a .netrc file saved in the home directory. If credentials are not found, an interactive prompt will allow you to input credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5abe3ece-2239-483c-949a-351819b04573",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = earthaccess.login(persist=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d44acb-5832-4cec-8ae1-6d1a266129c3",
   "metadata": {},
   "source": [
    "### If desired, print all available PACE Level 3 short names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e927d4b-e636-4d71-85fb-7b6d0ec2b743",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    results_oci = earthaccess.search_datasets(instrument=\"oci\",processing_level_id='3')\n",
    "    results_harp = earthaccess.search_datasets(instrument=\"harp2\",processing_level_id='3')\n",
    "    results_spex = earthaccess.search_datasets(instrument=\"spexone\",processing_level_id='3')\n",
    "    results=results_oci + results_harp + results_spex\n",
    "    for item in results:\n",
    "        summary = item.summary()\n",
    "        print(summary[\"short-name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd04ef05-edf4-4ea4-94f5-a4ee087ec713",
   "metadata": {},
   "source": [
    "### Identify and search product, specify plotting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f3cc1d4-4970-4172-a680-57b267ef10c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of granules:  37\n"
     ]
    }
   ],
   "source": [
    "tspan = (\"2025-08-01\", \"2025-09-07\")\n",
    "bbox = (-35., -30., 20., 10.0)\n",
    "granule_name=\"*.Day.*0p1deg*\",  # Daily, 8-day or monthly: Day, 8D or MO | Resolution: 0p1deg or 0.4km\n",
    "\n",
    "TAG='SE Atlantic smoke: PACE OCI smoke aerosol index'\n",
    "short_name=\"PACE_OCI_L3M_AER_UAA_NRT\"\n",
    "variable_name='NUV_AerosolIndex'\n",
    "plot_range = (0,5)\n",
    "colormap='hot_r'\n",
    "save_interpolation=True\n",
    "\n",
    "outdir='SEAtlantic_smoke_transport_202508_202509'\n",
    "results = earthaccess.search_data(\n",
    "    short_name=short_name,\n",
    "    temporal=tspan,\n",
    "    granule_name=granule_name\n",
    ")\n",
    "print('Number of granules: ',len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d5d3d7b-b1b5-43b1-93ff-c8f64e7a8ef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bf055f931824a1782b99493793b8a07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QUEUEING TASKS | :   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a56049a121f44987ae35ea30b22d97b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PROCESSING TASKS | :   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab356a8de53a4d5f97aa825b593a6a2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "COLLECTING RESULTS | :   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "paths = earthaccess.open(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d90d264-84ef-403e-b747-421ee98cc58f",
   "metadata": {},
   "source": [
    "### Open and read file(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e8dc4f4-25c5-4709-b543-abea52129302",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def read_l3_files(file_paths, variable_name, bbox=None):\n",
    "    \"\"\"\n",
    "    Read Level 3 files and combine them\n",
    "    \n",
    "    Parameters:\n",
    "        file_paths: list of file paths from earthaccess.open()\n",
    "        variable_name: name of the variable to extract\n",
    "        bbox: tuple of (lon_min, lat_min, lon_max, lat_max) for subsetting\n",
    "    \n",
    "    Returns:\n",
    "        combined_ds: xarray Dataset with the variable and coordinates\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"Reading {len(file_paths)} L3 files...\")\n",
    "    \n",
    "    datasets = []\n",
    "    \n",
    "    for i, file_path in enumerate(file_paths):\n",
    "        try:\n",
    "            print(f\"Processing file {i+1}/{len(file_paths)}\")\n",
    "            \n",
    "            # Extract date from filename\n",
    "            import os\n",
    "            import re\n",
    "            filename = os.path.basename(str(file_path))\n",
    "            print(f\"  Filename: {filename}\")\n",
    "            \n",
    "            # Extract date from PACE L3 filename pattern: PACE_OCI.YYYYMMDD.L3m...\n",
    "            date_match = re.search(r'PACE_OCI\\.(\\d{8})\\.', filename)\n",
    "            if date_match:\n",
    "                date_str = date_match.group(1)\n",
    "                filename_date = f\"{date_str[:4]}-{date_str[4:6]}-{date_str[6:8]}\"\n",
    "                print(f\"  Extracted date: {filename_date}\")\n",
    "            else:\n",
    "                print(f\"  Warning: Could not extract date from filename\")\n",
    "                # Fallback: try any 8-digit pattern\n",
    "                date_match = re.search(r'(\\d{8})', filename)\n",
    "                if date_match:\n",
    "                    date_str = date_match.group(1)\n",
    "                    filename_date = f\"{date_str[:4]}-{date_str[4:6]}-{date_str[6:8]}\"\n",
    "                    print(f\"  Extracted date (fallback): {filename_date}\")\n",
    "                else:\n",
    "                    print(f\"  Could not extract date, skipping file\")\n",
    "                    continue\n",
    "            \n",
    "            # Read the L3 file - try different group structures\n",
    "            ds = None\n",
    "            \n",
    "            # Try common L3 group structures\n",
    "            for group in [None, 'geophysical_data', 'science_data']:\n",
    "                try:\n",
    "                    if group is None:\n",
    "                        ds = xr.open_dataset(file_path)\n",
    "                    else:\n",
    "                        ds = xr.open_dataset(file_path, group=group)\n",
    "                    \n",
    "                    # Check if our variable is in this group\n",
    "                    if variable_name in ds.variables:\n",
    "                        print(f\"  Found '{variable_name}' in {group or 'root'} group\")\n",
    "                        break\n",
    "                    else:\n",
    "                        ds = None\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    continue\n",
    "            \n",
    "            if ds is None:\n",
    "                print(f\"  Could not find variable '{variable_name}' in file {i+1}\")\n",
    "                continue\n",
    "            \n",
    "            # Create correct time coordinate from filename\n",
    "            correct_time = np.datetime64(filename_date)\n",
    "            \n",
    "            # Add or replace time coordinate\n",
    "            if 'time' in ds.dims:\n",
    "                # Replace existing time coordinate\n",
    "                ds = ds.assign_coords(time=[correct_time])\n",
    "            else:\n",
    "                # Add time dimension if it doesn't exist\n",
    "                ds = ds.expand_dims('time')\n",
    "                ds = ds.assign_coords(time=[correct_time])\n",
    "            \n",
    "            print(f\"  Set time coordinate to: {correct_time}\")\n",
    "            \n",
    "            # Get coordinate information\n",
    "            # L3 files usually have lat/lon as 1D coordinate arrays\n",
    "            if 'lat' in ds.coords:\n",
    "                lat_coord = 'lat'\n",
    "            elif 'latitude' in ds.coords:\n",
    "                lat_coord = 'latitude'\n",
    "            else:\n",
    "                print(f\"  Could not find latitude coordinate in file {i+1}\")\n",
    "                continue\n",
    "                \n",
    "            if 'lon' in ds.coords:\n",
    "                lon_coord = 'lon'\n",
    "            elif 'longitude' in ds.coords:\n",
    "                lon_coord = 'longitude'\n",
    "            else:\n",
    "                print(f\"  Could not find longitude coordinate in file {i+1}\")\n",
    "                continue\n",
    "            \n",
    "            # Subset by bounding box if provided\n",
    "            if bbox is not None:\n",
    "                lon_min, lat_min, lon_max, lat_max = bbox\n",
    "                \n",
    "                # Select data within bounding box\n",
    "                ds_subset = ds.sel(\n",
    "                    {lon_coord: slice(lon_min, lon_max),\n",
    "                     lat_coord: slice(lat_min, lat_max)}\n",
    "                )\n",
    "                \n",
    "                print(f\"  Subset to bbox: {ds_subset[variable_name].shape}\")\n",
    "            else:\n",
    "                ds_subset = ds\n",
    "            \n",
    "            # Standardize coordinate names\n",
    "            if lat_coord != 'latitude':\n",
    "                ds_subset = ds_subset.rename({lat_coord: 'latitude'})\n",
    "            if lon_coord != 'longitude':\n",
    "                ds_subset = ds_subset.rename({lon_coord: 'longitude'})\n",
    "            \n",
    "            datasets.append(ds_subset)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error reading file {i+1}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if not datasets:\n",
    "        print(\"No datasets successfully loaded!\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Successfully loaded {len(datasets)} datasets\")\n",
    "    \n",
    "    # Sort datasets by time before combining (in case files were not in order)\n",
    "    datasets.sort(key=lambda x: x.time.values[0])\n",
    "    \n",
    "    # Combine datasets along time dimension if multiple files\n",
    "    if len(datasets) == 1:\n",
    "        combined_ds = datasets[0]\n",
    "    else:\n",
    "        try:\n",
    "            # Concatenate along time dimension\n",
    "            combined_ds = xr.concat(datasets, dim='time')\n",
    "            print(\"Combined datasets along time dimension\")\n",
    "        except:\n",
    "            try:\n",
    "                # If concatenation fails, try to merge\n",
    "                combined_ds = xr.merge(datasets)\n",
    "                print(\"Merged datasets\")\n",
    "            except Exception as e:\n",
    "                print(f\"Could not combine datasets: {e}\")\n",
    "                print(\"Using first dataset only\")\n",
    "                combined_ds = datasets[0]\n",
    "    \n",
    "    # Print final time coordinate information\n",
    "    if 'time' in combined_ds.coords:\n",
    "        print(f\"Final time coordinates:\")\n",
    "        for i, time_val in enumerate(combined_ds.time.values):\n",
    "            print(f\"  {i}: {time_val}\")\n",
    "    \n",
    "    # Print info about the combined dataset\n",
    "    print(f\"Final dataset shape for '{variable_name}': {combined_ds[variable_name].shape}\")\n",
    "    print(f\"Coordinate ranges:\")\n",
    "    print(f\"  Longitude: {combined_ds.longitude.min().values:.2f} to {combined_ds.longitude.max().values:.2f}\")\n",
    "    print(f\"  Latitude: {combined_ds.latitude.min().values:.2f} to {combined_ds.latitude.max().values:.2f}\")\n",
    "    \n",
    "    return combined_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1744cb2-7db9-43d7-b6c1-b781e4473da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 37 L3 files...\n",
      "Processing file 1/37\n",
      "  Filename: PACE_OCI.20250801.L3m.DAY.AER_UAA.V3_1.0p1deg.NRT.nc>\n",
      "  Extracted date: 2025-08-01\n"
     ]
    }
   ],
   "source": [
    "dataset = read_l3_files(paths, variable_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f71fd0-bf53-4313-afa7-4f0498a37ee8",
   "metadata": {},
   "source": [
    "### Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab78c54a-49a4-4134-aec1-8305485dbf92",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_pace_l3_data_daily(dataset, variable_name, plot_range=None, colormap='viridis', \n",
    "                           outdir='.', title_tag='PACE L3', bbox=None, \n",
    "                           percentile_range=(2, 98), nan_color='black',\n",
    "                           ncols=None, figsize_per_plot=(6, 5)):\n",
    "    \"\"\"\n",
    "    Plot Level 3 data with separate subplot for each day\n",
    "    \n",
    "    Parameters:\n",
    "        dataset: xarray Dataset from read_pace_l3_files()\n",
    "        variable_name: name of variable to plot\n",
    "        plot_range: tuple of (vmin, vmax) or None for auto-range\n",
    "        colormap: matplotlib colormap name\n",
    "        outdir: output directory\n",
    "        title_tag: tag for plot title\n",
    "        bbox: tuple of (lon_min, lat_min, lon_max, lat_max) for plot extent only\n",
    "        percentile_range: percentiles for auto-ranging\n",
    "        nan_color: color for NaN values\n",
    "        ncols: number of columns for subplot grid (auto-calculated if None)\n",
    "        figsize_per_plot: size of each individual subplot\n",
    "    \"\"\"\n",
    "    \n",
    "    if dataset is None or variable_name not in dataset.variables:\n",
    "        print(\"No data to plot!\")\n",
    "        return None, None\n",
    "    \n",
    "    # Get the data variable\n",
    "    data_var = dataset[variable_name]\n",
    "    \n",
    "    print(f\"Original data shape: {data_var.shape}\")\n",
    "    \n",
    "    # Check if time dimension exists\n",
    "    if 'time' not in data_var.dims:\n",
    "        print(\"No time dimension found - creating single plot\")\n",
    "        return plot_pace_l3_data_single(dataset, variable_name, plot_range, colormap, \n",
    "                                       outdir, title_tag, bbox, percentile_range, nan_color)\n",
    "    \n",
    "    # Get number of time steps\n",
    "    n_times = len(data_var.time)\n",
    "    print(f\"Found {n_times} time steps\")\n",
    "    \n",
    "    if n_times == 1:\n",
    "        print(\"Only one time step - creating single plot\")\n",
    "        return plot_pace_l3_data_single(dataset, variable_name, plot_range, colormap, \n",
    "                                       outdir, title_tag, bbox, percentile_range, nan_color)\n",
    "    \n",
    "    # Calculate subplot grid dimensions\n",
    "    if ncols is None:\n",
    "        ncols = min(4, n_times)  # Max 4 columns\n",
    "    nrows = int(np.ceil(n_times / ncols))\n",
    "    \n",
    "    print(f\"Creating {nrows}x{ncols} subplot grid\")\n",
    "    \n",
    "    # Calculate figure size\n",
    "    fig_width = ncols * figsize_per_plot[0]\n",
    "    fig_height = nrows * figsize_per_plot[1]\n",
    "    \n",
    "    # Create figure with subplots\n",
    "    fig = plt.figure(figsize=(fig_width, fig_height))\n",
    "    \n",
    "    # Subset data for plotting if bbox is specified\n",
    "    if bbox is not None:\n",
    "        lon_min, lat_min, lon_max, lat_max = bbox\n",
    "        print(f\"Subsetting data to bbox: lon {lon_min} to {lon_max}, lat {lat_min} to {lat_max}\")\n",
    "        \n",
    "        try:\n",
    "            lons = dataset.longitude.values\n",
    "            lats = dataset.latitude.values\n",
    "            \n",
    "            if lon_max < lon_min:  # bbox crosses dateline\n",
    "                lon_mask = (lons >= lon_min) | (lons <= lon_max)\n",
    "            else:\n",
    "                lon_mask = (lons >= lon_min) & (lons <= lon_max)\n",
    "            \n",
    "            lat_mask = (lats >= lat_min) & (lats <= lat_max)\n",
    "            \n",
    "            if np.sum(lon_mask) == 0 or np.sum(lat_mask) == 0:\n",
    "                print(\"Warning: No data points within specified bbox, using full dataset\")\n",
    "                plot_extent = None\n",
    "                plot_data = data_var\n",
    "            else:\n",
    "                plot_data = data_var.sel(\n",
    "                    longitude=data_var.longitude[lon_mask],\n",
    "                    latitude=data_var.latitude[lat_mask]\n",
    "                )\n",
    "                plot_extent = [lon_min, lon_max, lat_min, lat_max]\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error during subsetting: {e}\")\n",
    "            plot_extent = None\n",
    "            plot_data = data_var\n",
    "    else:\n",
    "        plot_data = data_var\n",
    "        lon_min, lon_max = float(dataset.longitude.min()), float(dataset.longitude.max())\n",
    "        lat_min, lat_max = float(dataset.latitude.min()), float(dataset.latitude.max())\n",
    "        plot_extent = [lon_min, lon_max, lat_min, lat_max]\n",
    "    \n",
    "    # Calculate plot range using all time steps\n",
    "    if plot_range is None:\n",
    "        valid_data = plot_data.values[~np.isnan(plot_data.values)]\n",
    "        if len(valid_data) == 0:\n",
    "            print(\"Warning: No valid data found!\")\n",
    "            vmin, vmax = 0, 1\n",
    "        else:\n",
    "            vmin = np.percentile(valid_data, percentile_range[0])\n",
    "            vmax = np.percentile(valid_data, percentile_range[1])\n",
    "            print(f\"Auto-calculated range for all days: {vmin:.3f} to {vmax:.3f}\")\n",
    "    else:\n",
    "        vmin, vmax = plot_range\n",
    "        print(f\"Using specified range: {vmin} to {vmax}\")\n",
    "    \n",
    "    # Create colormap\n",
    "    base_cmap = plt.colormaps.get_cmap(colormap)\n",
    "    cmap_with_nan = base_cmap.copy()\n",
    "    \n",
    "    # Handle NaN colors for cartopy\n",
    "    if nan_color.lower() in ['black', 'k']:\n",
    "        nan_facecolor = 'black'\n",
    "        cmap_with_nan.set_bad(alpha=0)\n",
    "    elif nan_color.lower() in ['transparent', 'none']:\n",
    "        nan_facecolor = 'white'\n",
    "        cmap_with_nan.set_bad(alpha=0)\n",
    "    else:\n",
    "        nan_facecolor = nan_color\n",
    "        cmap_with_nan.set_bad(alpha=0)\n",
    "    \n",
    "    # Create subplots for each day\n",
    "    axes = []\n",
    "    ims = []\n",
    "    \n",
    "    for i in range(n_times):\n",
    "        # Create subplot\n",
    "        ax = fig.add_subplot(nrows, ncols, i+1, projection=ccrs.PlateCarree())\n",
    "        axes.append(ax)\n",
    "        \n",
    "        # Set background color for NaN values\n",
    "        ax.set_facecolor(nan_facecolor)\n",
    "        \n",
    "        # Add map features with BLACK boundaries and land\n",
    "        ax.add_feature(cfeature.COASTLINE, linewidth=0.5, edgecolor='black')\n",
    "        ax.add_feature(cfeature.BORDERS, linewidth=0.5, edgecolor='black')\n",
    "        ax.add_feature(cfeature.STATES, linewidth=0.3, edgecolor='black')\n",
    "        ax.add_feature(cfeature.LAND, color='black', alpha=0.3)  # Black land\n",
    "        ax.add_feature(cfeature.OCEAN, color='lightblue', alpha=0.2)\n",
    "        \n",
    "        # Set extent\n",
    "        if plot_extent is not None:\n",
    "            ax.set_extent(plot_extent, crs=ccrs.PlateCarree())\n",
    "        \n",
    "        # Get data for this time step\n",
    "        day_data = plot_data.isel(time=i)\n",
    "        \n",
    "        # Plot the data\n",
    "        im = ax.pcolormesh(\n",
    "            day_data.longitude, \n",
    "            day_data.latitude, \n",
    "            day_data,\n",
    "            transform=ccrs.PlateCarree(),\n",
    "            cmap=cmap_with_nan,\n",
    "            vmin=vmin,\n",
    "            vmax=vmax,\n",
    "            shading='auto'\n",
    "        )\n",
    "        ims.append(im)\n",
    "        \n",
    "        # Format date for title\n",
    "        time_val = plot_data.time.values[i]\n",
    "        try:\n",
    "            # Handle different time formats\n",
    "            if hasattr(time_val, 'strftime'):\n",
    "                date_str = time_val.strftime('%Y-%m-%d')\n",
    "            elif hasattr(time_val, 'astype'):\n",
    "                # Handle numpy datetime64\n",
    "                date_str = str(time_val.astype('datetime64[D]'))\n",
    "            else:\n",
    "                date_str = str(time_val)[:10]\n",
    "        except:\n",
    "            date_str = str(time_val)[:10]\n",
    "        \n",
    "        # Set title with date\n",
    "        ax.set_title(f'{title_tag}\\n{date_str}', fontsize=10, pad=10)\n",
    "        \n",
    "        # Add gridlines for larger subplots\n",
    "        if figsize_per_plot[0] >= 6:\n",
    "            gl = ax.gridlines(draw_labels=True, linewidth=0.3, alpha=0.5)\n",
    "            gl.top_labels = False\n",
    "            gl.right_labels = False\n",
    "            gl.xlabel_style = {'size': 8}\n",
    "            gl.ylabel_style = {'size': 8}\n",
    "    \n",
    "    # Add a single colorbar for all subplots\n",
    "    # Position colorbar on the right side of the figure\n",
    "    cbar_ax = fig.add_axes([0.92, 0.15, 0.02, 0.7])  # [left, bottom, width, height]\n",
    "    cbar = fig.colorbar(ims[0], cax=cbar_ax, orientation='vertical')\n",
    "    cbar.set_label(variable_name, fontsize=12)\n",
    "    \n",
    "    # Add main title with date range\n",
    "    time_range = f\"{str(plot_data.time.values[0])[:10]} to {str(plot_data.time.values[-1])[:10]}\"\n",
    "    fig.suptitle(f'{title_tag} - Daily Views\\n{time_range}', fontsize=16, y=0.95)\n",
    "    \n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(right=0.9, top=0.88)  # Make room for colorbar and title\n",
    "    \n",
    "    # Generate filename\n",
    "    if bbox:\n",
    "        bbox_str = f\"{bbox[0]:.0f}_{bbox[1]:.0f}_{bbox[2]:.0f}_{bbox[3]:.0f}\"\n",
    "        region_tag = \"subset\"\n",
    "    else:\n",
    "        bbox_str = \"global\" \n",
    "        region_tag = \"global\"\n",
    "    \n",
    "    start_date = str(plot_data.time.values[0])[:10].replace('-', '')\n",
    "    end_date = str(plot_data.time.values[-1])[:10].replace('-', '')\n",
    "    filename = f\"PACE_L3_{variable_name}_daily_{start_date}_{end_date}_{region_tag}_{bbox_str}.png\"\n",
    "    \n",
    "    save_path = os.path.join(outdir, filename)\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    print(f\"Daily subplot plot saved to: {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return fig, axes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b007c4-ef83-48d1-acf5-6c601f4da89c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_pace_l3_data_single(dataset, variable_name, plot_range=None, colormap='viridis', \n",
    "                            outdir='.', title_tag='PACE L3', bbox=None, \n",
    "                            percentile_range=(2, 98), nan_color='black'):\n",
    "    \"\"\"Single plot version with black boundaries and date in title\"\"\"\n",
    "    \n",
    "    if dataset is None or variable_name not in dataset.variables:\n",
    "        print(\"No data to plot!\")\n",
    "        return None, None\n",
    "    \n",
    "    data_var = dataset[variable_name]\n",
    "    \n",
    "    # Handle time dimension if present\n",
    "    if 'time' in data_var.dims:\n",
    "        if len(data_var.time) == 1:\n",
    "            plot_data = data_var.isel(time=0)\n",
    "            time_val = data_var.time.values[0]\n",
    "        else:\n",
    "            plot_data = data_var.mean(dim='time')\n",
    "            time_val = data_var.time.values[0]  # Use first date for title\n",
    "    else:\n",
    "        plot_data = data_var\n",
    "        time_val = None\n",
    "    \n",
    "    # Format date for title\n",
    "    if time_val is not None:\n",
    "        try:\n",
    "            if hasattr(time_val, 'strftime'):\n",
    "                date_str = time_val.strftime('%Y-%m-%d')\n",
    "            elif hasattr(time_val, 'astype'):\n",
    "                date_str = str(time_val.astype('datetime64[D]'))\n",
    "            else:\n",
    "                date_str = str(time_val)[:10]\n",
    "        except:\n",
    "            date_str = str(time_val)[:10]\n",
    "    else:\n",
    "        date_str = \"Unknown date\"\n",
    "    \n",
    "    # Subset data for plotting if bbox is specified\n",
    "    if bbox is not None:\n",
    "        lon_min, lat_min, lon_max, lat_max = bbox\n",
    "        try:\n",
    "            lons = dataset.longitude.values\n",
    "            lats = dataset.latitude.values\n",
    "            \n",
    "            if lon_max < lon_min:\n",
    "                lon_mask = (lons >= lon_min) | (lons <= lon_max)\n",
    "            else:\n",
    "                lon_mask = (lons >= lon_min) & (lons <= lon_max)\n",
    "            \n",
    "            lat_mask = (lats >= lat_min) & (lats <= lat_max)\n",
    "            \n",
    "            if np.sum(lon_mask) == 0 or np.sum(lat_mask) == 0:\n",
    "                plot_extent = None\n",
    "            else:\n",
    "                plot_data = plot_data.sel(\n",
    "                    longitude=plot_data.longitude[lon_mask],\n",
    "                    latitude=plot_data.latitude[lat_mask]\n",
    "                )\n",
    "                plot_extent = [lon_min, lon_max, lat_min, lat_max]\n",
    "        except:\n",
    "            plot_extent = None\n",
    "    else:\n",
    "        lon_min, lon_max = float(dataset.longitude.min()), float(dataset.longitude.max())\n",
    "        lat_min, lat_max = float(dataset.latitude.min()), float(dataset.latitude.max())\n",
    "        plot_extent = [lon_min, lon_max, lat_min, lat_max]\n",
    "    \n",
    "    # Calculate plot range\n",
    "    if plot_range is None:\n",
    "        valid_data = plot_data.values[~np.isnan(plot_data.values)]\n",
    "        if len(valid_data) == 0:\n",
    "            vmin, vmax = 0, 1\n",
    "        else:\n",
    "            vmin = np.percentile(valid_data, percentile_range[0])\n",
    "            vmax = np.percentile(valid_data, percentile_range[1])\n",
    "    else:\n",
    "        vmin, vmax = plot_range\n",
    "    \n",
    "    # Create the plot\n",
    "    fig = plt.figure(figsize=(15, 10))\n",
    "    ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "    \n",
    "    # Handle NaN colors\n",
    "    base_cmap = plt.colormaps.get_cmap(colormap)\n",
    "    cmap_with_nan = base_cmap.copy()\n",
    "    \n",
    "    if nan_color.lower() in ['black', 'k']:\n",
    "        ax.set_facecolor('black')\n",
    "        cmap_with_nan.set_bad(alpha=0)\n",
    "    elif nan_color.lower() in ['transparent', 'none']:\n",
    "        ax.set_facecolor('white')\n",
    "        cmap_with_nan.set_bad(alpha=0)\n",
    "    else:\n",
    "        ax.set_facecolor(nan_color)\n",
    "        cmap_with_nan.set_bad(alpha=0)\n",
    "    \n",
    "    # Add map features with BLACK boundaries and land\n",
    "    ax.add_feature(cfeature.COASTLINE, linewidth=0.5, edgecolor='black')\n",
    "    ax.add_feature(cfeature.BORDERS, linewidth=0.5, edgecolor='black')\n",
    "    ax.add_feature(cfeature.STATES, linewidth=0.3, edgecolor='black')\n",
    "    ax.add_feature(cfeature.LAND, color='lightbrown', alpha=0.3)  \n",
    "    ax.add_feature(cfeature.OCEAN, color='lightblue', alpha=0.3)\n",
    "    \n",
    "    # Set extent\n",
    "    if plot_extent is not None:\n",
    "        ax.set_extent(plot_extent, crs=ccrs.PlateCarree())\n",
    "    \n",
    "    # Plot the data\n",
    "    im = ax.pcolormesh(\n",
    "        plot_data.longitude, \n",
    "        plot_data.latitude, \n",
    "        plot_data,\n",
    "        transform=ccrs.PlateCarree(),\n",
    "        cmap=cmap_with_nan,\n",
    "        vmin=vmin,\n",
    "        vmax=vmax,\n",
    "        shading='auto'\n",
    "    )\n",
    "    \n",
    "    # Add colorbar\n",
    "    cbar = plt.colorbar(im, ax=ax, orientation='vertical', shrink=0.8, pad=0.05)\n",
    "    cbar.set_label(variable_name, fontsize=12)\n",
    "    \n",
    "    # Add title with date\n",
    "    plt.title(f'{title_tag}\\n{date_str}', fontsize=14)\n",
    "    ax.set_xlabel('Longitude', fontsize=12)\n",
    "    ax.set_ylabel('Latitude', fontsize=12)\n",
    "    \n",
    "    # Add gridlines\n",
    "    gl = ax.gridlines(draw_labels=True, linewidth=0.5, alpha=0.5)\n",
    "    gl.top_labels = False\n",
    "    gl.right_labels = False\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Generate filename\n",
    "    if bbox:\n",
    "        bbox_str = f\"{bbox[0]:.0f}_{bbox[1]:.0f}_{bbox[2]:.0f}_{bbox[3]:.0f}\"\n",
    "        region_tag = \"subset\"\n",
    "    else:\n",
    "        bbox_str = \"global\"\n",
    "        region_tag = \"global\"\n",
    "    \n",
    "    date_str_clean = date_str.replace('-', '')\n",
    "    filename = f\"PACE_L3_{variable_name}_{date_str_clean}_{region_tag}_{bbox_str}.png\"\n",
    "    \n",
    "    save_path = os.path.join(outdir, filename)\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    print(f\"Plot saved to: {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b805f6-9d12-4cf5-8cef-3c2b3b1636b0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def create_l3_animation(dataset, variable_name, plot_range=None, colormap='viridis', \n",
    "                            outdir='.', title_tag='PACE L3', bbox=None, \n",
    "                            percentile_range=(2, 98), nan_color='black',\n",
    "                            figsize=(12, 8), duration=1000, loop=True):\n",
    "    \"\"\"\n",
    "    Create an animated GIF of PACE Level 3 data cycling through each day\n",
    "    \n",
    "    Parameters:\n",
    "        dataset: xarray Dataset from read_l3_files()\n",
    "        variable_name: name of variable to plot\n",
    "        plot_range: tuple of (vmin, vmax) or None for auto-range\n",
    "        colormap: matplotlib colormap name\n",
    "        outdir: output directory\n",
    "        title_tag: tag for plot title\n",
    "        bbox: tuple of (lon_min, lat_min, lon_max, lat_max) for plot extent only\n",
    "        percentile_range: percentiles for auto-ranging\n",
    "        nan_color: color for NaN values\n",
    "        figsize: figure size (width, height)\n",
    "        duration: duration per frame in milliseconds\n",
    "        loop: whether to loop the animation\n",
    "    \n",
    "    Returns:\n",
    "        filename of saved GIF\n",
    "    \"\"\"\n",
    "    \n",
    "    if dataset is None or variable_name not in dataset.variables:\n",
    "        print(\"No data to animate!\")\n",
    "        return None\n",
    "    \n",
    "    # Get the data variable\n",
    "    data_var = dataset[variable_name]\n",
    "    \n",
    "    print(f\"Original data shape: {data_var.shape}\")\n",
    "    \n",
    "    # Check if time dimension exists\n",
    "    if 'time' not in data_var.dims:\n",
    "        print(\"No time dimension found - cannot create animation\")\n",
    "        return None\n",
    "    \n",
    "    # Get number of time steps\n",
    "    n_times = len(data_var.time)\n",
    "    print(f\"Found {n_times} time steps for animation\")\n",
    "    \n",
    "    if n_times == 1:\n",
    "        print(\"Only one time step - cannot create animation\")\n",
    "        return None\n",
    "    \n",
    "    # Subset data for plotting if bbox is specified\n",
    "    if bbox is not None:\n",
    "        lon_min, lat_min, lon_max, lat_max = bbox\n",
    "        print(f\"Applying bbox constraint: lon {lon_min} to {lon_max}, lat {lat_min} to {lat_max}\")\n",
    "        \n",
    "        try:\n",
    "            lons = dataset.longitude.values\n",
    "            lats = dataset.latitude.values\n",
    "            \n",
    "            if lon_max < lon_min:  # bbox crosses dateline\n",
    "                lon_mask = (lons >= lon_min) | (lons <= lon_max)\n",
    "            else:\n",
    "                lon_mask = (lons >= lon_min) & (lons <= lon_max)\n",
    "            \n",
    "            lat_mask = (lats >= lat_min) & (lats <= lat_max)\n",
    "            \n",
    "            if np.sum(lon_mask) == 0 or np.sum(lat_mask) == 0:\n",
    "                print(\"Warning: No data points within specified bbox, using full dataset\")\n",
    "                plot_extent = [lon_min, lon_max, lat_min, lat_max]  # Still use bbox for extent\n",
    "                plot_data = data_var\n",
    "            else:\n",
    "                plot_data = data_var.sel(\n",
    "                    longitude=data_var.longitude[lon_mask],\n",
    "                    latitude=data_var.latitude[lat_mask]\n",
    "                )\n",
    "                plot_extent = [lon_min, lon_max, lat_min, lat_max]\n",
    "                print(f\"Data subset to shape: {plot_data.shape}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error during subsetting: {e}, using full dataset\")\n",
    "            plot_extent = [lon_min, lon_max, lat_min, lat_max]  # Still use bbox for extent\n",
    "            plot_data = data_var\n",
    "    else:\n",
    "        plot_data = data_var\n",
    "        lon_min, lon_max = float(dataset.longitude.min()), float(dataset.longitude.max())\n",
    "        lat_min, lat_max = float(dataset.latitude.min()), float(dataset.latitude.max())\n",
    "        plot_extent = [lon_min, lon_max, lat_min, lat_max]\n",
    "        print(\"Using full dataset extent\")\n",
    "    \n",
    "    # Calculate plot range using the (possibly subsetted) data\n",
    "    if plot_range is None:\n",
    "        valid_data = plot_data.values[~np.isnan(plot_data.values)]\n",
    "        if len(valid_data) == 0:\n",
    "            print(\"Warning: No valid data found!\")\n",
    "            vmin, vmax = 0, 1\n",
    "        else:\n",
    "            vmin = np.percentile(valid_data, percentile_range[0])\n",
    "            vmax = np.percentile(valid_data, percentile_range[1])\n",
    "            actual_min = np.min(valid_data)\n",
    "            actual_max = np.max(valid_data)\n",
    "            print(f\"Data range: {actual_min:.4f} to {actual_max:.4f}\")\n",
    "            print(f\"Auto-calculated plot range ({percentile_range[0]}-{percentile_range[1]}%): {vmin:.3f} to {vmax:.3f}\")\n",
    "    else:\n",
    "        vmin, vmax = plot_range\n",
    "        print(f\"Using specified plot range: {vmin} to {vmax}\")\n",
    "    \n",
    "    # Create colormap with NaN handling\n",
    "    print(f\"Using colormap: {colormap}\")\n",
    "    base_cmap = plt.colormaps.get_cmap(colormap)\n",
    "    cmap_with_nan = base_cmap.copy()\n",
    "    \n",
    "    # Handle NaN colors for cartopy\n",
    "    if nan_color.lower() in ['black', 'k']:\n",
    "        nan_facecolor = 'black'\n",
    "        cmap_with_nan.set_bad(alpha=0)\n",
    "    elif nan_color.lower() in ['transparent', 'none']:\n",
    "        nan_facecolor = 'white'\n",
    "        cmap_with_nan.set_bad(alpha=0)\n",
    "    else:\n",
    "        nan_facecolor = nan_color\n",
    "        cmap_with_nan.set_bad(alpha=0)\n",
    "    \n",
    "    print(f\"NaN areas will appear as: {nan_facecolor}\")\n",
    "    \n",
    "    # Create the figure (will be reused for each frame)\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    \n",
    "    # Store temporary files for frames\n",
    "    temp_files = []\n",
    "    \n",
    "    print(\"Creating animation frames...\")\n",
    "    \n",
    "    for i in range(n_times):\n",
    "        print(f\"  Creating frame {i+1}/{n_times}\")\n",
    "        \n",
    "        # Clear the figure\n",
    "        fig.clear()\n",
    "        \n",
    "        # Create subplot with cartopy projection\n",
    "        ax = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree())\n",
    "        \n",
    "        # Set background color for NaN values\n",
    "        ax.set_facecolor(nan_facecolor)\n",
    "        \n",
    "        # Add map features with BLACK boundaries and land (as specified)\n",
    "        ax.add_feature(cfeature.COASTLINE, linewidth=0.5, edgecolor='black')\n",
    "        ax.add_feature(cfeature.BORDERS, linewidth=0.5, edgecolor='black')\n",
    "        ax.add_feature(cfeature.STATES, linewidth=0.3, edgecolor='black')\n",
    "        ax.add_feature(cfeature.LAND, color='black', alpha=0.3)\n",
    "        ax.add_feature(cfeature.OCEAN, color='lightblue', alpha=0.2)\n",
    "        \n",
    "        # Set map extent using bbox\n",
    "        ax.set_extent(plot_extent, crs=ccrs.PlateCarree())\n",
    "        \n",
    "        # Get data for this time step\n",
    "        day_data = plot_data.isel(time=i)\n",
    "        \n",
    "        # Plot the data using specified colormap and range\n",
    "        im = ax.pcolormesh(\n",
    "            day_data.longitude, \n",
    "            day_data.latitude, \n",
    "            day_data,\n",
    "            transform=ccrs.PlateCarree(),\n",
    "            cmap=cmap_with_nan,  # Use specified colormap\n",
    "            vmin=vmin,           # Use specified/calculated range\n",
    "            vmax=vmax,           # Use specified/calculated range\n",
    "            shading='auto'\n",
    "        )\n",
    "        \n",
    "        # Add colorbar\n",
    "        cbar = plt.colorbar(im, ax=ax, orientation='vertical', \n",
    "                           shrink=0.8, pad=0.05)\n",
    "        cbar.set_label(variable_name, fontsize=12)\n",
    "        \n",
    "        # Format date for title\n",
    "        time_val = plot_data.time.values[i]\n",
    "        try:\n",
    "            if hasattr(time_val, 'strftime'):\n",
    "                date_str = time_val.strftime('%Y-%m-%d')\n",
    "            elif hasattr(time_val, 'astype'):\n",
    "                date_str = str(time_val.astype('datetime64[D]'))\n",
    "            else:\n",
    "                date_str = str(time_val)[:10]\n",
    "        except:\n",
    "            date_str = str(time_val)[:10]\n",
    "        \n",
    "        # Set title with date\n",
    "        plt.title(f'{title_tag}\\n{date_str}', fontsize=14, pad=20)\n",
    "        ax.set_xlabel('Longitude', fontsize=12)\n",
    "        ax.set_ylabel('Latitude', fontsize=12)\n",
    "        \n",
    "        # Add gridlines\n",
    "        gl = ax.gridlines(draw_labels=True, linewidth=0.3, alpha=0.5)\n",
    "        gl.top_labels = False\n",
    "        gl.right_labels = False\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save frame as temporary image\n",
    "        temp_filename = f\"temp_frame_{i:03d}.png\"\n",
    "        temp_path = os.path.join(outdir, temp_filename)\n",
    "        plt.savefig(temp_path, dpi=150, bbox_inches='tight', facecolor='white')\n",
    "        temp_files.append(temp_path)\n",
    "    \n",
    "    # Create GIF from frames\n",
    "    print(\"Assembling GIF animation...\")\n",
    "    \n",
    "    try:        \n",
    "        # Load all frames\n",
    "        images = []\n",
    "        for temp_file in temp_files:\n",
    "            img = Image.open(temp_file)\n",
    "            images.append(img)\n",
    "        \n",
    "        # Generate output filename\n",
    "        if bbox:\n",
    "            bbox_str = f\"{bbox[0]:.0f}_{bbox[1]:.0f}_{bbox[2]:.0f}_{bbox[3]:.0f}\"\n",
    "            region_tag = \"subset\"\n",
    "        else:\n",
    "            bbox_str = \"global\"\n",
    "            region_tag = \"global\"\n",
    "        \n",
    "        start_date = str(plot_data.time.values[0])[:10].replace('-', '')\n",
    "        end_date = str(plot_data.time.values[-1])[:10].replace('-', '')\n",
    "        \n",
    "        # Include colormap and range in filename for clarity\n",
    "        range_str = f\"{vmin:.2f}_{vmax:.2f}\".replace('.', 'p').replace('-', 'neg')\n",
    "        gif_filename = f\"PACE_L3_{variable_name}_{colormap}_{range_str}_animation_{start_date}_{end_date}_{region_tag}_{bbox_str}.gif\"\n",
    "        gif_path = os.path.join(outdir, gif_filename)\n",
    "        \n",
    "        # Save as GIF\n",
    "        images[0].save(\n",
    "            gif_path,\n",
    "            save_all=True,\n",
    "            append_images=images[1:],\n",
    "            duration=duration,\n",
    "            loop=0 if loop else 1,\n",
    "            optimize=True\n",
    "        )\n",
    "        \n",
    "        print(f\"GIF animation saved to: {gif_path}\")\n",
    "        print(f\"  - Colormap: {colormap}\")\n",
    "        print(f\"  - Range: {vmin:.3f} to {vmax:.3f}\")\n",
    "        print(f\"  - Extent: {plot_extent}\")\n",
    "        print(f\"  - Duration: {duration}ms per frame\")\n",
    "        \n",
    "        # Clean up temporary files\n",
    "        for temp_file in temp_files:\n",
    "            try:\n",
    "                os.remove(temp_file)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        plt.close(fig)\n",
    "        \n",
    "        return gif_path\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\"PIL (Pillow) not installed. Install with: pip install Pillow\")\n",
    "        print(\"Temporary frame files saved for manual GIF creation:\")\n",
    "        for temp_file in temp_files:\n",
    "            print(f\"  {temp_file}\")\n",
    "        return None\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating GIF: {e}\")\n",
    "        print(\"Temporary frame files saved:\")\n",
    "        for temp_file in temp_files:\n",
    "            print(f\"  {temp_file}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193b7579-4070-427e-8ac0-27735dd148a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slow animation (2 seconds per frame) Fast animation has duration = 500 for 0.5 sec per frame\n",
    "gif_path = create_l3_animation(\n",
    "    dataset, \n",
    "    variable_name,           # \n",
    "    plot_range=plot_range,   # \n",
    "    colormap=colormap,       # \n",
    "    outdir=outdir,           # \n",
    "    title_tag=TAG,           # \n",
    "    bbox=bbox,               # \n",
    "    duration=250,           # 0.5 seconds per frame\n",
    "    figsize=(16, 8)         # Larger figure\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8fe386-75b3-43d8-9d1c-9fd4d143358a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-day subplot plot (automatic grid)\n",
    "fig, axes = plot_pace_l3_data_daily(\n",
    "    dataset, \n",
    "    variable_name, \n",
    "    plot_range=plot_range,\n",
    "    colormap=colormap,\n",
    "    outdir=outdir,\n",
    "    title_tag=TAG, \n",
    "    bbox=bbox,\n",
    "    ncols=2,  \n",
    "    figsize_per_plot=(10, 6),  # Larger subplots\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef83d264-970a-46d3-918d-5beab407ae0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378cd60c-3414-42ea-928e-bc81db97b349",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_var = dataset[variable_name]\n",
    "print(data_var.time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd37538-8462-4992-90df-57427dcf80bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
