{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c06837f7",
   "metadata": {},
   "source": [
    "## PACE Rapid Response Workflow\n",
    "\n",
    "#### Basic Steps\n",
    "- Use worldview to identify an event and region of interest to examine (basic before/after)\n",
    "- define lat lon bounds, and time range for pre- and post-event averages\n",
    "- earthdata search using parameters. Open the first one by itself to establish gridding params\n",
    "- use dask to open all the pre-event granules\n",
    "- use dask to open all the post-event granules\n",
    "- make some initial analysis plots\n",
    "- return pre and post dataframes to user, to allow them to make more custom plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb2ae344",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mkehrli/miniforge3/envs/hackweek/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import cartopy.crs as ccrs\n",
    "import earthaccess\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from matplotlib.colors import LogNorm\n",
    "import cmocean\n",
    "from dask.distributed import Client\n",
    "from matplotlib.patches import Rectangle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87028b11",
   "metadata": {},
   "source": [
    "### Case Study\n",
    "\n",
    "Hurricane Erin, look at chl-a before and after hurricane off FL coast\n",
    "- as Carlos mentioned last meeting, hurricanes tend to increase productivity\n",
    "Timeline (using worldview): \n",
    "- Hurricane off florida/gulf stream PACE imagery on AUG 20\n",
    "- Aug 21, hurricane passed and clear imagery\n",
    "- Aug 18/19 hurricane not there yet\n",
    "\n",
    "*post Aug 21, there is a PACE safehold so no data. But, the imagery from Aug21 immediately post hurricane is enough for this example script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "404cc24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User definitions:\n",
    "\n",
    "pre_tspan = (\"2025-08-18\", \"2025-08-20\")\n",
    "post_tspan = (\"2025-08-21\", \"2025-08-22\")\n",
    "\n",
    "min_lon = -82\n",
    "min_lat = 27.8\n",
    "max_lon = -70\n",
    "max_lat = 32.1\n",
    "\n",
    "suite_name=\"PACE_OCI_L2_BGC_NRT\" # oci suite name\n",
    "var_name = \"chlor_a\"\n",
    "\n",
    "##\n",
    "bbox = (min_lon, min_lat, max_lon, max_lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2437ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Functions\n",
    "def grid_match(path, dst_crs, dst_shape, dst_transform):\n",
    "    \"\"\"Reproject a Level-2 granule to match a Level-3M-ish granule.\"\"\"\n",
    "    dt = xr.open_datatree(path)\n",
    "    da = dt[\"geophysical_data\"][\"chlor_a\"]\n",
    "    da = da.rio.set_spatial_dims(\"pixels_per_line\", \"number_of_lines\")\n",
    "    da = da.rio.set_crs(\"epsg:4326\")\n",
    "    da = da.rio.reproject(\n",
    "        dst_crs,\n",
    "        shape=dst_shape,\n",
    "        transform=dst_transform,\n",
    "        src_geoloc_array=(\n",
    "            dt[\"navigation_data\"][\"longitude\"],\n",
    "            dt[\"navigation_data\"][\"latitude\"],\n",
    "        ),\n",
    "    )\n",
    "    da = da.rename({\"x\":\"longitude\", \"y\":\"latitude\"})\n",
    "    return da\n",
    "\n",
    "def time_from_attr(ds):\n",
    "    \"\"\"Set the start time attribute as a dataset variable.\n",
    " \n",
    "    Parameters\n",
    "    ----------\n",
    "    ds\n",
    "        a dataset corresponding to a Level-2 granule\n",
    "    \"\"\"\n",
    "    datetime = ds.attrs[\"time_coverage_start\"].replace(\"Z\", \"\")\n",
    "    ds[\"time\"] = ((), np.datetime64(datetime, \"ns\"))\n",
    "    ds = ds.set_coords(\"time\")\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cd379b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''One large cell to load in all relevant pre-event and post-event granules\n",
    "Steps:\n",
    "- Earth access search to make lists of pre and post event files\n",
    "- Open first entry of list manually, manipulate to L3M-like format and store relevant grid configuration info\n",
    "- Using dask, open pre and post event granules, recast to L3M-like mapped format, trim to spatial extent, combine 2 datasets\n",
    "- Make some default plots to visualize Pre and Post event data\n",
    "'''\n",
    "\n",
    "pre_results = earthaccess.search_data(\n",
    "    short_name=suite_name,\n",
    "    temporal=pre_tspan,\n",
    "    bounding_box=bbox,# logic to select central point of bounding box\n",
    ")\n",
    "#pre_paths = earthaccess.open(pre_results) # MK changed to below to test download\n",
    "pre_paths = earthaccess.download(pre_results, local_path=\"data\")\n",
    "print(\" Number of pre-event granules: \"+str(len(pre_results)))\n",
    "\n",
    "post_results = earthaccess.search_data(\n",
    "    short_name=suite_name,\n",
    "    temporal=post_tspan,\n",
    "    bounding_box=bbox,# logic to select central point of bounding box\n",
    ")\n",
    "#post_paths = earthaccess.open(post_results) # MK changed to below to test download\n",
    "post_paths = earthaccess.download(post_results, local_path=\"data\")\n",
    "print(\" Number of post-event granules: \"+str(len(post_results)))\n",
    "\n",
    "# Part 1: load first file in pre_paths, manipulate to L3M-like, store geo info\n",
    "\n",
    "datatree = xr.open_datatree(pre_paths[0])\n",
    "dataset = xr.merge(datatree.to_dict().values())\n",
    "dataset = dataset.set_coords((\"longitude\", \"latitude\"))\n",
    "\n",
    "var_data = dataset[var_name]# use code from dask_gridding notebook to transform L2 granule to L3M-like grid\n",
    "var_data = var_data.rio.set_spatial_dims(\"pixels_per_line\", \"number_of_lines\")\n",
    "var_data = var_data.rio.write_crs(\"epsg:4326\")\n",
    "var_L3M = var_data.rio.reproject(\n",
    "    dst_crs=\"epsg:4326\",\n",
    "    src_geoloc_array=(\n",
    "        var_data.coords[\"longitude\"],\n",
    "        var_data.coords[\"latitude\"],\n",
    "    ),\n",
    ")\n",
    "var_L3M = var_L3M.rename({\"x\":\"longitude\", \"y\":\"latitude\"})\n",
    "\n",
    "var_L3M_aoi = var_L3M.sel({\"longitude\": slice(bbox[0], bbox[2]),\"latitude\": slice(bbox[3], bbox[1])})\n",
    "\n",
    "crs = var_L3M_aoi.rio.crs# set mapping parameters from newly transformed file, to use when opening the rest with dask\n",
    "shape = var_L3M_aoi.rio.shape\n",
    "transform = var_L3M_aoi.rio.transform()\n",
    "\n",
    "# part 2: using dask, open all the data in pre_paths and post_paths\n",
    "# 2a load pre event files\n",
    "client = Client()\n",
    "pre_futures = client.map(grid_match,pre_paths,dst_crs=crs,dst_shape=shape,dst_transform=transform)\n",
    "kwargs = {\"combine\": \"nested\", \"concat_dim\": \"time\"}\n",
    "pre_attrs = xr.open_mfdataset(pre_paths, preprocess=time_from_attr, **kwargs)\n",
    "pre_data = xr.combine_nested(client.gather(pre_futures), concat_dim=\"time\")# open  4 files. they are stored in same xarray dataset at different \"time\" coordinates \n",
    "pre_data[\"time\"] = pre_attrs[\"time\"]\n",
    "#client.close()\n",
    "print('loaded pre event files')\n",
    "\n",
    "# 2b post event files\n",
    "client = Client()\n",
    "post_futures = client.map(grid_match,post_paths,dst_crs=crs,dst_shape=shape,dst_transform=transform)\n",
    "kwargs = {\"combine\": \"nested\", \"concat_dim\": \"time\"}\n",
    "post_attrs = xr.open_mfdataset(post_paths, preprocess=time_from_attr, **kwargs)\n",
    "post_data = xr.combine_nested(client.gather(post_futures), concat_dim=\"time\")# open a 4 files. they are stored in same xarray dataset at different \"time\" coordinates \n",
    "post_data[\"time\"] = post_attrs[\"time\"]\n",
    "client.close()\n",
    "print('loaded post event files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd9da4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(15, 6), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "ax[0].gridlines(draw_labels={\"left\": \"y\", \"bottom\": \"x\"})\n",
    "plot = pre_data.mean(\"time\").plot(x=\"longitude\", y=\"latitude\" , cbar_kwargs={'label': 'Chlor mg/m3', 'shrink':0.5}, cmap=cmocean.cm.haline,norm=LogNorm(vmin=.01, vmax=5),  ax=ax[0], robust=True)\n",
    "ax[0].set_xlim(bbox[0]-3,bbox[2]+3,)\n",
    "ax[0].set_ylim(bbox[1]-3,bbox[3]+3)\n",
    "ax[0].coastlines()\n",
    "ax[0].set_title('pre_hurricane_8/18 & 8/19')\n",
    "\n",
    "\n",
    "ax[1].gridlines(draw_labels={\"left\": \"y\", \"bottom\": \"x\"})\n",
    "plot = post_data.mean(\"time\").plot(x=\"longitude\", y=\"latitude\", cbar_kwargs={'label': 'Chlor mg/m3', 'shrink':0.5}, cmap=cmocean.cm.haline,norm=LogNorm(vmin=.01, vmax=5),  ax=ax[1], robust=True)\n",
    "ax[1].set_xlim(bbox[0]-3,bbox[2]+3,)\n",
    "ax[1].set_ylim(bbox[1]-3,bbox[3]+3)\n",
    "ax[1].coastlines()\n",
    "ax[1].set_title('post_hurricane 8/21')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e209b54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the pre and post event data. first, mask both to only pixels where data is available before and after the hurricane\n",
    "# then, mask each where it's values are greater or less than\n",
    "\n",
    "pre_mean = pre_data.mean(\"time\")\n",
    "post_mean = post_data.mean(\"time\")\n",
    "\n",
    "post_mean['longitude'] = post_mean['longitude'].round(5)# round lat/lon to 5 decimals, was having issues with floats at large # of decimals not being exactly the same\n",
    "post_mean['latitude'] = post_mean['latitude'].round(5)\n",
    "pre_mean['longitude'] = pre_mean['longitude'].round(5)\n",
    "pre_mean['latitude'] = pre_mean['latitude'].round(5)\n",
    "\n",
    "# Create a mask where both datasets have valid values\n",
    "mask = ~np.isnan(post_mean) & ~np.isnan(pre_mean)\n",
    "\n",
    "# Apply mask to both datasets\n",
    "post_mean_mask = post_mean.where(mask)\n",
    "pre_mean_mask = pre_mean.where(mask)\n",
    "\n",
    "# new mask to show where post > pre and vice versa\n",
    "mask2 = post_mean<pre_mean\n",
    "mask3 = post_mean>pre_mean\n",
    "\n",
    "# Apply mask to both datasets\n",
    "pre_mean_mask = pre_mean_mask.where(mask2)# locations where chla is higher pre hurricane\n",
    "post_mean_mask = post_mean_mask.where(mask3)# locations where chla is higher post hurricane\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 6), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "ax[0].gridlines(draw_labels={\"left\": \"y\", \"bottom\": \"x\"})\n",
    "plot = pre_mean_mask.plot(x=\"longitude\", y=\"latitude\" , cbar_kwargs={'label': 'Chlor mg/m3', 'shrink':0.5}, cmap=cmocean.cm.haline,norm=LogNorm(vmin=.01, vmax=5),  ax=ax[0], robust=True)\n",
    "ax[0].set_xlim(bbox[0]-3,bbox[2]+3,)\n",
    "ax[0].set_ylim(bbox[1]-3,bbox[3]+3)\n",
    "ax[0].coastlines()\n",
    "ax[0].set_title('pre_hurricane higher chla')\n",
    "\n",
    "ax[1].gridlines(draw_labels={\"left\": \"y\", \"bottom\": \"x\"})\n",
    "plot = post_mean_mask.plot(x=\"longitude\", y=\"latitude\", cbar_kwargs={'label': 'Chlor mg/m3', 'shrink':0.5}, cmap=cmocean.cm.haline,norm=LogNorm(vmin=.01, vmax=5),  ax=ax[1], robust=True)\n",
    "ax[1].set_xlim(bbox[0]-3,bbox[2]+3,)\n",
    "ax[1].set_ylim(bbox[1]-3,bbox[3]+3)\n",
    "ax[1].coastlines()\n",
    "ax[1].set_title('post_hurricane higher chla')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d83c137",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hackweek",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
